seed: 0
device: '0'
num_workers: 8
use_cudnn_benchmark: true
weights: ./exp_log/train/2024-11-15T100033_ESTDAN_v3_BSD_2ms16ms/checkpoints/ckpt-epoch-0550.pth.tar
# weights: ~
eval_batch_size: 1
prefix: '_R-ESTDANv3_wo_clean_e550_'
phase: test  # train, resume, test
exp_path: ./exp_log

dataset:
  test:
    # BSD_1ms8ms:
    #   image_blur_path: ../dataset/BSD_1ms8ms/%s/blur/%s/%s.png
    #   image_clear_path: ../dataset/BSD_1ms8ms/%s/GT/%s/%s.png
    #   json_file_path: datasets/BSD_1ms8ms_test.json
    
    # BSD_1ms8ms_comp:
    #   image_blur_path: ../dataset/BSD_1ms8ms_comp/%s/blur/%s/%s.png
    #   image_clear_path: ../dataset/BSD_1ms8ms/%s/GT/%s/%s.png
    #   json_file_path: datasets/BSD_1ms8ms_test.json
    
    Mi11Lite:
      image_blur_path: ../dataset/Mi11Lite/%s/%s/%s.png
      image_clear_path: ../dataset/Mi11Lite/%s/%s/%s.png
      json_file_path: datasets/mi11lite.json

network:
  arch: ESTDAN_v3
  use_stack: false
  # use_otho_edge: true
  n_sequence: 3

  in_channels: 3
  out_channels: 3
  n_resblock: 3
  n_feat: 32
  kernel_size: 5
  sobel_out_channels: 2  # for ESTDAN
  use_cleaning: false # for ESTDANv3
  is_sequential_cleaning: false
  is_fix_cleaning: false
  dynamic_refine_thres: 1.5 # 255 1.5
  n_cleaning_blocks: 5 # 20
  mid_channels: 32 # 64

raft:
  config_file: ../STDAN_modified/mmflow/configs/raft/raft_8x2_100k_mixed_368x768.py
  checkpoint: ../STDAN_modified/mmflow/checkpoints/raft_8x2_100k_mixed_368x768.pth

# train_transform:
#   ColorJitter: 
#     color_adjust_para: [0.2, 0.15, 0.3, 0.1] # brightness, contrast, saturation, hue
#   Normalize:
#     mean: [0.0, 0.0, 0.0]
#     std: [255.0, 255.0, 255.0]
#   RandomCrop:
#     crop_size: [256, 256]  # Crop image size: height, width
#   RandomVerticalFlip:
#   RandomHorizontalFlip:
#   RandomGaussianNoise:
#     gaussian_para: [0, 1.0e-4]  # mu, std_var
  
#   # for blur only transform 
#   UnsharpMasking:
#     kernel_size: 51
#     sigma: 0
#     weight: 0.5
#     threshold: 10

#   RandomBlur:
#     params:
#       kernel_size: [7, 9, 11, 13, 15, 17, 19, 21]
#       kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso',
#                     'plateau_iso', 'plateau_aniso', 'sinc']
#       kernel_prob: [0.405, 0.225, 0.108, 0.027, 0.108, 0.027, 0.1]
#       sigma_x: [0.2, 3]
#       sigma_y: [0.2, 3]
#       rotate_angle: [-3.1416, 3.1416]
#       beta_gaussian: [0.5, 4]
#       beta_plateau: [1, 2]
#       sigma_x_step: 0.02
#       sigma_y_step: 0.02
#       rotate_angle_step: 0.31416
#       beta_gaussian_step: 0.05
#       beta_plateau_step: 0.1
#       omega_step: 0.0628
  
#   RandomNoise:
#     params:
#       noise_type: ['gaussian', 'poisson']
#       noise_prob: [0.5, 0.5]
#       gaussian_sigma: [1, 30]
#       gaussian_gray_noise_prob: 0.4
#       poisson_scale: [0.05, 3]
#       poisson_gray_noise_prob: 0.4
#       gaussian_sigma_step: 0.1
#       poisson_scale_step: 0.005

#   RandomJPEGCompression:
#     params:
#       quality: [30, 95]
#       quality_step: 3

#   RandomVideoCompression:
#     params:
#       codec: ['libx264', 'h264', 'mpeg4']
#       codec_prob: [1/3, 1/3, 1/3]
#       bitrate: [1.0e+4, 1.0e+5]



eval_transform:
  Normalize:
    mean: [0.0, 0.0, 0.0]
    std: [255.0, 255.0, 255.0]

loss:
  # L1Loss:
  #   func: l1Loss
  #   weight: 1
  CharbonnierLoss:
    func: CharbonnierLoss
    weight: 1
  CleaningCharbonnierLoss:
    func: CleaningCharbonnierLoss
    weight: 1
  WarpMSELoss:
    func: warp_loss
    weight: 0.05
  FFTLoss:
    func: FFTLoss
    weight: 0.05 

  
eval:
  valid_freq: 50  # 50
  visualize_freq: 100 # 50
  save_input_img: true
  save_output_img: true
  save_flow: true
  use_tensorboard: true
  metrics:
    PSNR:
      crop_border: 0
      max_order: 255.0
    # SSIM:
    # LPIPS: