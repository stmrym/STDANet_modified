seed: 0
device: '0'
num_workers: 8
use_cudnn_benchmark: true
# weights: ./exp_log/train/2024-12-11T210210_ESTDAN_VT2_BSD_3ms24ms_GOPRO/checkpoints/ckpt-epoch-*.pth.tar
# weights: ~
test_weights: ./exp_log/train/2025-01-21T050901_STDAN_VT2_CM_BSD_3ms24ms_GOPRO/checkpoints/ckpt-epoch-*.pth.tar
train_batch_size: 8
eval_batch_size: 1
prefix: 'VT2_CM'
phase: test  # [train], [resume], or [test]
exp_path: ./exp_log

dataset:
  train:
    BSD_3ms24ms:
      image_blur_path: ../dataset/BSD_3ms24ms/%s/blur/%s/%s.png
      image_clear_path: ../dataset/BSD_3ms24ms/%s/GT/%s/%s.png # %s, %s, %s: phase, seq_name, image_name template
      json_file_path: datasets/BSD_3ms24ms_train_1000.json

    GOPRO:
      image_blur_path: ../dataset/GOPRO_Large/%s/%s/blur_gamma/%s.png
      image_clear_path: ../dataset/GOPRO_Large/%s/%s/sharp/%s.png
      json_file_path: datasets/GOPRO_train_1000.json


  val:
    Mi11Lite:
      image_blur_path: ../dataset/Mi11Lite/%s/%s/%s.png
      image_clear_path: ../dataset/Mi11Lite/%s/%s/%s.png
      json_file_path: datasets/mi11lite.json


  test:
    # Mi11Lite:
    #   image_blur_path: ../dataset/Mi11Lite/%s/%s/%s.png
    #   image_clear_path: ../dataset/Mi11Lite/%s/%s/%s.png
    #   json_file_path: datasets/mi11lite.json
    
    BSD_3ms24ms:
      image_blur_path: ../dataset/BSD_3ms24ms/%s/blur/%s/%s.png
      image_clear_path: ../dataset/BSD_3ms24ms/%s/GT/%s/%s.png # %s, %s, %s: phase, seq_name, image_name template
      json_file_path: datasets/BSD_3ms24ms_test.json

    GOPRO:
      image_blur_path: ../dataset/GOPRO_Large/%s/%s/blur_gamma/%s.png
      image_clear_path: ../dataset/GOPRO_Large/%s/%s/sharp/%s.png
      json_file_path: datasets/GOPRO_test.json


network:
  arch: STDAN
  use_stack: false
  n_sequence: 3

  in_channels: 3
  out_channels: 3
  n_resblock: 3
  n_feat: 32
  kernel_size: 5
  sobel_out_channels: 2  # for ESTDAN
  
  # === for cleaning module ===
  use_cleaning: true # select [true] or [false]

  is_sequential_cleaning: false
  is_fix_cleaning: false
  dynamic_refine_thres: 255
  n_cleaning_blocks: 5 # original(Real-BasicVSR): 20
  mid_channels: 32 # original(Real-BasicVSR): 64


train_transform:
  # === Common Transform ===
  ColorJitter: 
    color_adjust_para: [0.2, 0.15, 0.3, 0.1] # brightness, contrast, saturation, hue
  Normalize:
    mean: [0.0, 0.0, 0.0]
    std: [255.0, 255.0, 255.0]
  RandomCrop:
    crop_size: [256, 256]  # Crop image size: height, width
  RandomVerticalFlip:
  RandomHorizontalFlip:
  RandomGaussianNoise:
    gaussian_para: [0, 1.0e-4]  # mu, std_var
  
  # ====  for VT2 ===== 
  # UnsharpMasking:
  #   kernel_size_l: [3, 5, 7, 9, 11]
  #   sigma: 0
  #   weight_prob: [0, 4]
  #   threshold: 10

  # RandomVideoCompression:
  #   params:
  #     codec: ['libx264', 'h264', 'mpeg4']
  #     codec_prob: [1/3, 1/3, 1/3]
  #     bitrate: [1.0e+4, 1.0e+5]

  # ===  for VT1 ====
  # UnsharpMasking:
  #   kernel_size_l: [51]
  #   sigma: 0
  #   weight_prob: [0.5]
  #   threshold: 40
  
  # RandomBlur:
  #   params:
  #     kernel_size: [7, 9, 11, 13, 15, 17, 19, 21]
  #     kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso',
  #                   'plateau_iso', 'plateau_aniso', 'sinc']
  #     kernel_prob: [0.405, 0.225, 0.108, 0.027, 0.108, 0.027, 0.1]
  #     sigma_x: [0.2, 3]
  #     sigma_y: [0.2, 3]
  #     rotate_angle: [-3.1416, 3.1416]
  #     beta_gaussian: [0.5, 4]
  #     beta_plateau: [1, 2]
  #     sigma_x_step: 0.02
  #     sigma_y_step: 0.02
  #     rotate_angle_step: 0.31416
  #     beta_gaussian_step: 0.05
  #     beta_plateau_step: 0.1
  #     omega_step: 0.0628
  
  # RandomNoise:
  #   params:
  #     noise_type: ['gaussian', 'poisson']
  #     noise_prob: [0.5, 0.5]
  #     gaussian_sigma: [1, 30]
  #     gaussian_gray_noise_prob: 0.4
  #     poisson_scale: [0.05, 3]
  #     poisson_gray_noise_prob: 0.4
  #     gaussian_sigma_step: 0.1
  #     poisson_scale_step: 0.005

  # RandomJPEGCompression:
  #   params:
  #     quality: [60, 95]   # 30, 95
  #     quality_step: 3

  # RandomVideoCompression:
  #   params:
  #     codec: ['libx264', 'h264', 'mpeg4']
  #     codec_prob: [1/3, 1/3, 1/3]
  #     bitrate: [1.0e+4, 1.0e+5]


eval_transform:
  Normalize:
    mean: [0.0, 0.0, 0.0]
    std: [255.0, 255.0, 255.0]

loss:
  L1Loss: # L1 Loss L_l1
    func: l1Loss
    weight: 1
  # CharbonnierLoss:  # Not in use now
  #   func: CharbonnierLoss
  #   weight: 1
  CleaningCharbonnierLoss: # Cleaning Loss L_p
    func: CleaningCharbonnierLoss
    weight: 1
  WarpMSELoss:  # Warp Loss L_w
    func: warp_loss
    weight: 0.05
  FFTLoss:  # Frequency Reconstruction Loss L_f
    func: FFTLoss
    weight: 0.01
  

train:
  use_percept_loss: false
  motion_requires_grad: true
  sobel_requires_grad: true
  n_epochs: 1201
  save_freq: 50 # 50
  cleaning_fix_epoch: 2001  # Valid for when using cleaning module
  optimization:
    learning_rate: 1.0e-4
    lr_milestones: 
      - 400
      - 600
      - 800
      - 1000
      - 1200
      - 1400
      - 1600
      - 1800
      - 2000
    lr_decay: 0.5
    momentum: 0.9
    beta: 0.999
    bias_decay: 0.0
    weight_decay: 0.0
  
eval:
  valid_freq: 50
  visualize_freq: 100
  save_input_img: true  # save input or pre-input image (when using cleaning module) 
  save_output_img: true # save output image
  use_tensorboard: true
  metrics:
    PSNR:
    SSIM:
    LPIPS:
    # NIQE:
    # LR:
      # use_denoise: false